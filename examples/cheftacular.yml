
mode:                   'devops'
initial_environment:    'staging' #the initial environment all commands are run in without an env setting flag
ruby_version:           'ruby-2.2.2'
deploy_user:            'deploy'
cheftacular_chef_user:  'hiplogiq'
chef_server_url:        'https://chef.socialcentiv.net'
ssl_verify:             'false'
wrapper_cookbooks:      'HiplogiqDeploy' #comma delim string of wrapper cookbooks to do clean_cookbooks on
strict_version_checks:  'true'  # when true, the gem will check rubygems once per day to see if there's a new version and prevent execution until this new version is bundled
auditing:               'true'  # when true, the gem will collect and send auditing data about all commands that are passed to the gem that will hit your chef server
base_file_path:         '/var/www/vhosts' #the base file path the repos are stored on for each server
default_swap_location:  '/mnt/1GB.swap' #default location of the swapfile build on all systems (used for cft restart_swap)
backup_directory:       '/mnt/postgresqlbackups/backups' #This is only used for the backup stateless command, can be left blank if other backup plans are being used
backup_filesystem:      'backup_gem' #valid entries are backup_gem | raw
backup_server:          'first_production_slave' #tells the backup command what server to fetch the backup data from. The string 'first_production_slave' is parsed into a TLD / local ip
chef_client_version:    '11.16.4' #version of chef-client to bootstrap on the remote servers
data_bag_key_file:      'data_bag_key' #name of the data bag key file in the ~/.chef folder for workstations
server_pass_length:     20
default_flavor_name:    '1 GB Performance' #When booting servers, this flavor name is used if a flavor is not set in some way
preferred_cloud:        'rackspace'    #preferred cloud to interact with (uses the default -> authentication bag as storage for the auth creds)
preferred_cloud_region: 'dfw'          #preferred cloud region to interact with
preferred_cloud_os:     'ubuntu'       #can be centos|coreos|debian|fedora|redhat|ubuntu|vyatta . Bear in mind not all OSes have supported bootstraps at the moment
preferred_cloud_image:  'Ubuntu 14.04' #preferred cloud image to install, can use custom built images here as well
virtualization_mode:    'PV' #on rackspace cloud, set your default virtualization mode to this (only PV or PVHVM are supported)

#RVM
install_rvm_on_boot:    'true' #'true'|'false' If true, this will cause RVM to be installed for the deploy_user on boot, this makes managing RVM via cookbook impossible.
rvm_gpg_key:            '409B6B1796C275462A1703113804BB82D39DC0E3'

#the first comma in the list of log_locs is what is tailable, the others are only loggable
role_maps: #role maps for log tailing
  sensu_server_role:    
    role_name:    'sensu_server'
    log_location: '/var/log/sensu/sensu-server.log'
  graphite_server_role: 
    role_name:    'graphite_server'
    log_location: '/var/log/carbon-cache/current'
  worker_server_role:
    role_name:    'worker'
    log_location: '/var/log/syslog,|current_repo_location|/log/delayed_job.log' #commas will pull logs from multiple locations. |current_repo_location| acts as an alias for a role's default repo location

repositories:
  apiscentiv: #this row is reserved for nicknames, preferably nicknames that eliminate any hyphens in the repo_name
    repo_name:                 'api-socialcentiv-com'
    database:                  'postgresql'
    application_database_user: 'socialcompass'
    stack:                     'ruby_on_rails'
    db_primary_host_role:      'db_primary'
    #custom_database_name:      'api-socialcentiv-com' #this key only needs to exist if your database is named differently from REPONAME_ENV
    restore_backup_file_name:  'PostgreSQL-api.sql'   #the file that the backup is usually stored in for the backup directory
    not_a_migration_message:   'config/local.yml file detected. Its environment variables will be merged on top of those from config/application.yml.'
    #backup_server:             'first_production_slave' #this key only needs to be set if the backup server (for this database) is different than the global_backup_server
    has_split_branches:        'true'
  myscentiv:
    repo_name:          'my-socialcentiv-com'
    database:           'none'
    stack:              'ruby_on_rails'
    has_split_branches: 'true'
  soccompass:
    repo_name: 'sc_agency'
    database:  'postgresql'
    stack:     'ruby_on_rails'
  socsift:
    repo_name: 'social_sift_app'
    database:  'postgresql'
    stack:     'ruby_on_rails'
  pg_data:
    repo_name: 'pg_data'
    database:  'postgresql'
    stack:     'ruby_on_rails'
  magellan:
    repo_name:                 'magellan_app'
    database:                  'postgresql'
    application_database_user: 'socialcompass'
    db_primary_host_role:      'db_primary'
    stack:                     'ruby_on_rails'
    restore_backup_file_name:  'PostgreSQL-magellan_app.sql'
    not_a_migration_message:   'config/local.yml file detected. Its environment variables will be merged on top of those from config/application.yml.'
    has_split_branches:        'true'
  uxangular:
    repo_name: 'SC_Angular'
    database:  'none'
    stack:     'nodejs'
  wpscentiv:
    repo_name: 'socialcentiv-com'
    database:  'mysql'
    stack:     'wordpress'
    specific_chef_passwords: #special keys that you want auto-generated for their repo by for the ENV chef_passwords bag, the value for them is their length
      mysql_root_pass:
      mysql_wwwscent_pass:
  all:
    repo_name: 'all'
    database:  'none' #we don't want to run migrations on an all deploy
    stack:     'all'

#if you are assigning environments with run lists *in addition to* chef environments, use this. Nodes should have 0-1 of these run list envs, no more.
# Also used for the update_split_branches command, a branch like split_staging is parsed into split-staging
run_list_environments:
  split_staging: 'splitstaging'
  split_a:       'splita'
  split_b:       'splitb'
  split_c:       'splitc'
  split_d:       'splitd'

#YAML array of the types of databases stored on your database primary
db_primary_backup_database_stacks: 
  - 'postgresql'

#nodes to initialize when cft devstaging command is run. All keys are optional but not assigning a flavor to a node will default it to the default_flavor_name key
#flavor:     the flavor the node will be booted with
#descriptor: optional string to be parsed into the node's config. Can be used to pair with load balancers, etc
#dns_config: by default, nodes are assigned NODE_NAME.ENV_TLD for their DNS, this can be overridden here. Both NODE_NAME and ENV_TLD are interpolated if used
env_boot_nodes:
  devstaging_nodes:
    apisc01d:     
      flavor:     "4 GB Performance"
      descriptor: "lb:api-socialcentiv-com"
    apisclbd:     
      dns_config: "api.ENV_TLD"
    workapisc01d: 
    wwwscentd:
    jobsd:        
    mysc01d:      
      flavor:     "2 GB Performance"
      descriptor: "lb:my-socialcentiv-com"
    mysclbd:      
      dns_config: "my.ENV_TLD"
    magelland:    
      descriptor: "lb:magellan_app"
    magellanlbd:  
      dns_config: "magellan.ENV_TLD"
    dbmasterd:    
      flavor:     "8 GB Performance"
      dns_config: "db.ENV_TLD"

#Extra data used for nodes when the "cft scale up" command is run. Digits in the node are parsed out and the node's name (without digits) must match 100% to trigger the custom data
scaling_nodes:
  apiscp:
    flavor:     "8 GB Performance"
    descriptor: "lb:api-socialcentiv-com"
  myscp:
    flavor:     "2 GB Performance"
    descriptor: "lb:my-socialcentiv-com"

#used in the test_env command, these are nodes that spun up for split-testing environments. They connect to their primary environment's database. IE a splitstaging node may connect to a staging database
split_env_nodes:
  apiscSPLITENV:
    flavor:      "4 GB Performance"
    descriptor:  "lb:api-socialcentiv-com"
  apiscSPLITENVlb:
    dns_config:  "api.ENV_TLD"
  workapiscSPLITENV:
  myscSPLITENV:
    flavor:      "2 GB Performance"
    descriptor:  "lb:my-socialcentiv-com"
  myscSPLITENVlb:
    dns_config:  "my.ENV_TLD"

global_chef_passwords: #passwords you want auto-generated for a chef_env for all repositories
  pg_pass: 20

#used in the get_haproxy_log command
haproxy_config:
  role_name:    'haproxy' #default role all haproxy servers will have
  default_port: 22002